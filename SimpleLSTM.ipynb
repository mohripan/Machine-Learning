{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleLSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOV7PtUAuQnEUbT5xrVcB7E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohripan/Machine-Learning/blob/main/SimpleLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk762SUCqP9X",
        "outputId": "44e584f2-9dbc-49c2-f611-af4fcbc71310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deeplearning.ai-pytorch'...\n",
            "remote: Enumerating objects: 231, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 231 (delta 1), reused 9 (delta 1), pack-reused 219\u001b[K\n",
            "Receiving objects: 100% (231/231), 68.32 MiB | 37.73 MiB/s, done.\n",
            "Resolving deltas: 100% (34/34), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/furkanu/deeplearning.ai-pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deeplearning.ai-pytorch/5- Sequence Models/Week 1/Dinosaur Island -- Character-level language model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2I3Txp6q33m",
        "outputId": "c0611f56-c974-40d8-f0f0-86f720d76523"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deeplearning.ai-pytorch/5- Sequence Models/Week 1/Dinosaur Island -- Character-level language model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "torch.set_printoptions(linewidth=200)"
      ],
      "metadata": {
        "id": "qkUKx5AjragV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "hidden_size = 50"
      ],
      "metadata": {
        "id": "rcuP87Pwrig5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DinoDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    with open('dinos.txt') as f:\n",
        "      content = f.read().lower()\n",
        "      self.vocab = sorted(set(content))\n",
        "      self.vocab_size = len(self.vocab)\n",
        "      self.lines = content.splitlines()\n",
        "    self.ch_to_idx = {c:i for i, c in enumerate(self.vocab)}\n",
        "    self.idx_to_ch = {i:c for i, c in enumerate(self.vocab)}\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    line = self.lines[index]\n",
        "    x_str = ' '+line\n",
        "    y_str = line + '\\n'\n",
        "    x = torch.zeros([len(x_str), self.vocab_size], dtype=torch.float)\n",
        "    y = torch.empty(len(x_str), dtype=torch.long)\n",
        "\n",
        "    y[0] = self.ch_to_idx[y_str[0]]\n",
        "\n",
        "    for i, (x_ch, y_ch) in enumerate(zip(x_str[1:], y_str[1:]), 1):\n",
        "      x[i][self.ch_to_idx[x_ch]] = 1\n",
        "      y[i] = self.ch_to_idx[y_ch]\n",
        "\n",
        "    return x, y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.lines)"
      ],
      "metadata": {
        "id": "xV4CNs_MrsQ0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trn_ds = DinoDataset()\n",
        "trn_dl = DataLoader(trn_ds, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "q3vJd5IrsspQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.linear_f = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.linear_u = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.linear_c = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.linear_o = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "\n",
        "    self.i2o = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, c_prev, h_prev, x):\n",
        "    combined = torch.cat([x, h_prev], 1)\n",
        "    f = torch.sigmoid(self.linear_f(combined))\n",
        "    u = torch.sigmoid(self.linear_u(combined))\n",
        "    c_tilde = torch.tanh(self.linear_c(combined))\n",
        "    c = f*c_prev + u*c_tilde\n",
        "    o = torch.sigmoid(self.linear_o(combined))\n",
        "    h = o*torch.tanh(c)\n",
        "    y = self.i2o(h)\n",
        "\n",
        "    return c, h, y"
      ],
      "metadata": {
        "id": "szYpmBics0TC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTM(trn_ds.vocab_size, hidden_size, trn_ds.vocab_size).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
      ],
      "metadata": {
        "id": "Soq3a0TBtt8F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_sample(sample_idxs):\n",
        "  print(trn_ds.idx_to_ch[sample_idxs[0]].upper(), end='')\n",
        "  [print(trn_ds.idx_to_ch[x], end='') for x in sample_idxs[1:]]"
      ],
      "metadata": {
        "id": "BQPW5R4Vt6Ky"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(model):\n",
        "  model.eval()\n",
        "  c_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
        "  h_prev = torch.zeros_like(c_prev)\n",
        "  x = c_prev.new_zeros([1, trn_ds.vocab_size])\n",
        "  sampled_indexes = []\n",
        "  idx = -1\n",
        "  n_chars = 1\n",
        "  newline_char_idx = trn_ds.ch_to_idx['\\n']\n",
        "  with torch.no_grad():\n",
        "    while n_chars != 50 and idx != newline_char_idx:\n",
        "      c_prev, h_prev, y_pred = model(c_prev, h_prev, x)\n",
        "      softmax_scores = torch.softmax(y_pred, 1).cpu().numpy().ravel()\n",
        "      np.random.seed(np.random.randint(1, 5000))\n",
        "      idx = np.random.choice(np.arange(trn_ds.vocab_size), p=softmax_scores)\n",
        "      sampled_indexes.append(idx)\n",
        "\n",
        "      x = (y_pred == y_pred.max(1)[0]).float()\n",
        "\n",
        "      n_chars += 1\n",
        "\n",
        "      if n_chars == 50:\n",
        "        sampled_indexes.append(newline_char_idx)\n",
        "\n",
        "  model.train()\n",
        "  return sampled_indexes"
      ],
      "metadata": {
        "id": "hkUkmWMPuJXb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loss_fn, optimizer):\n",
        "  model.train()\n",
        "  for line_num, (x, y) in enumerate(trn_dl):\n",
        "    loss = 0\n",
        "    optimizer.zero_grad()\n",
        "    c_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
        "    h_prev = torch.zeros_like(c_prev)\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    for i in range(x.shape[1]):\n",
        "      c_prev, h_prev, y_pred = model(c_prev, h_prev, x[:, i])\n",
        "      loss += loss_fn(y_pred, y[:, i])\n",
        "\n",
        "    if(line_num+1) % 100 == 0:\n",
        "      print_sample(sample(model))\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "vvKJYGHdvG_D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loss_fn, optimizer, dataset='dinos', epochs=1):\n",
        "  for i in range(1, epochs+1):\n",
        "    print(f'{\"-\"*20} Epoch {i} {\"-\"*20}')\n",
        "    train_one_epoch(model, loss_fn, optimizer)"
      ],
      "metadata": {
        "id": "LMtrlqaxvtOB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, loss_fn, optimizer, epochs=3)"
      ],
      "metadata": {
        "id": "3zMLBDfTwAiW",
        "outputId": "4b1e029a-8b14-44c9-897f-efe5019da8d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------- Epoch 1 --------------------\n",
            "\n",
            "Anhsourus\n",
            "Abinnapaurts\n",
            "Xmaasm\n",
            "Letmhcaurus\n",
            "Bstsaurus\n",
            "Tmpptaurus\n",
            "Asgubctpar\n",
            "Slictirus\n",
            "Brtsleaurus\n",
            "Pruaaurus\n",
            "Sltcauros\n",
            "Slgasaurus\n",
            "Stongosaurus\n",
            "Taiicaurus\n",
            "-------------------- Epoch 2 --------------------\n",
            "Agsoaaurus\n",
            "Sciusiurus\n",
            "Errlvaurus\n",
            "Jicrtcauros\n",
            "Mamasaurus\n",
            "Wrtasaurus\n",
            "Jvsposaurus\n",
            "Scrmturus\n",
            "Litenaurus\n",
            "Ugstoraurus\n",
            "Lrotaelamaurus\n",
            "Ctnaraurus\n",
            "Ahvrulaurus\n",
            "Rhysiosaurus\n",
            "Saogtaurus\n",
            "-------------------- Epoch 3 --------------------\n",
            "Ctnrasaosaurus\n",
            "Meurovpurus\n",
            "Jmaasatosaurus\n",
            "Cscgasahsaurus\n",
            "Meronrratoph\n",
            "Lanrasauras\n",
            "Anciil\n",
            "Tdiyrpurus\n",
            "Drtivaurus\n",
            "Inaesaonturus\n",
            "Ljspanros\n",
            "Puasturus\n",
            "Juuksourus\n",
            "Dtaomtclor\n",
            "Lltlalras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eozUW2ERwC_1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}